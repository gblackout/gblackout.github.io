<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Authors | Yuan Yang</title>
    <link>/authors/</link>
      <atom:link href="/authors/index.xml" rel="self" type="application/rss+xml" />
    <description>Authors</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 01 Jan 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Authors</title>
      <link>/authors/</link>
    </image>
    
    <item>
      <title>Hanjun Dai</title>
      <link>/authors/hanjun-dai/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/authors/hanjun-dai/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Le Song</title>
      <link>/authors/le-song/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/authors/le-song/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mayur Naik</title>
      <link>/authors/mayur-naik/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/authors/mayur-naik/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Xujie Si&lt;sup&gt;&amp;#42;&lt;/sup&gt;</title>
      <link>/authors/xujie-sisup#42/sup/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/authors/xujie-sisup#42/sup/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Yuan Yang</title>
      <link>/authors/yuan-yang/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/authors/yuan-yang/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Yuan Yang&lt;sup&gt;&amp;#42;&lt;/sup&gt;</title>
      <link>/authors/yuan-yangsup#42/sup/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/authors/yuan-yangsup#42/sup/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Carol Cheng</title>
      <link>/authors/carol-cheng/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/carol-cheng/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Christy Li</title>
      <link>/authors/christy-li/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/christy-li/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Eric Nyberg</title>
      <link>/authors/eric-nyberg/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/eric-nyberg/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Eric Xing</title>
      <link>/authors/eric-xing/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/eric-xing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hongbao Zhang</title>
      <link>/authors/hongbao-zhang/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/hongbao-zhang/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jingcheng Yu</title>
      <link>/authors/jingcheng-yu/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/jingcheng-yu/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pengtao Xie</title>
      <link>/authors/pengtao-xie/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/pengtao-xie/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Xiaoyao Xu</title>
      <link>/authors/xiaoyao-xu/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/xiaoyao-xu/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Xin Gao</title>
      <link>/authors/xin-gao/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/xin-gao/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Y. Yang</title>
      <link>/authors/y.-yang/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/y.-yang/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ye Hu</title>
      <link>/authors/ye-hu/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/ye-hu/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jianfei Chen</title>
      <link>/authors/jianfei-chen/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>/authors/jianfei-chen/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jun Zhu</title>
      <link>/authors/jun-zhu/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>/authors/jun-zhu/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Di Zhao</title>
      <link>/authors/di-zhao/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>/authors/di-zhao/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hong Yi Li</title>
      <link>/authors/hong-yi-li/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>/authors/hong-yi-li/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/admin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/admin/</guid>
      <description>&lt;p&gt;I&#39;m a research scientist at ByteDance. Previously, I was a Machine Learning PhD at Georgia Tech supervised by Prof.&lt;a href=&#34;https://fekri.ece.gatech.edu/&#34;&gt;Faramarz Fekri&lt;/a&gt; and Prof.&lt;a href=&#34;https://scholar.google.com/citations?user=Xl4E0CsAAAAJ&amp;amp;hl=en&#34;&gt;Le Song&lt;/a&gt;. I received my MS in Computational Data Science from CMU in 2017 and BEng in Software Engineering from Beihang Univ. in 2016.&lt;/p&gt;
&lt;p&gt;My research focuses on LLM, logic reasoning, and interpretable and data-efficient ML models:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I&#39;m interested in building new LLM architecture that manages life-long context and works like an intelligent OS&lt;/li&gt;
&lt;li&gt;I also work on LLM-based data synthesis and enhancing the LLMs with better reasoning and tool-using capabilities&lt;/li&gt;
&lt;li&gt;My previous study involves inductive and deductive logic reasoning on knowledge graphs and frameworks that use them for data labeling and adversarial defense.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/prj1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/prj1/</guid>
      <description>&lt;p&gt;Temporal data such as video and driving logs are widely studied in tasks such as video
understanding and autonomous driving.&lt;/p&gt;
&lt;p&gt;We develop a reasoning framework that detects inductive patterns in temporal data via neural-logic
methodology. The framework aims to assist the training of modern ML models by inducing patterns for accurate grounding
with fewer data. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Summarizing recipes from cooking instruction videos for caption generation.&lt;/li&gt;
&lt;li&gt;Detecting and summarizing human driver&#39;s behavior from the driving logs for imitation learning of an autonomous driving agent.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/prj2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/prj2/</guid>
      <description>&lt;p&gt;Modern ML models can achieve amazing performance in many tasks. However, they require a large amount of labeled data
to train and their outputs are not self-explanatory for human users.&lt;/p&gt;
&lt;p&gt;We study this problem for graph reasoning models. We propose a learning-by-asking
framework, namely LogicQA, that trains the model by interactively asking questions to an oracle. Under the hood,
verified questions are used to label the data automatically, leading to order of magnitude better data efficiency.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/prj3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/prj3/</guid>
      <description>&lt;p&gt;Deductive and inductive reasoning are the critical tasks for many knowledge graphs applications. The former learns
to infer new facts using the existing knowledge; the latter summarizes (or induces) the knowledge using the
existing facts. We studied and proposed GNN- and logic-based models to address these issues respectively.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/prj4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/prj4/</guid>
      <description>&lt;p&gt;Deep vision models are successfully employed in many applications, but they are vulnerable to adversarial
examples. Existing defense methods are either limited to specific attacks types or are too complex for practical models.&lt;/p&gt;
&lt;p&gt;To this end, we propose &lt;em&gt;logic adversarial defense&lt;/em&gt;, a framework that utilizes the scene graph of the image to detect
object labels that are out-of-place in the context. Our framework is model-agnostic and effective against localized
attacks such as &lt;em&gt;adversarial patch&lt;/em&gt;. Moreover, it produces human-readable explanations as to why the system is attacked.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/prj5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/prj5/</guid>
      <description>&lt;p&gt;One of the major bottlenecks for logic-based NLP systems is the lack of a reliable translation model that
maps natural language (NL) to the corresponding first-order logic (FOL) representation.&lt;/p&gt;
&lt;p&gt;We approach this longstanding challenge by harnessing the power of LLMs. We create a high-quality
sentence-level NL-FOL pair dataset (MALLS) from GPT-4. We then propose an SFT+RLHF framework that finetunes
LLaMA models for NL-FOL translation task. The resulting model, namely LogicLLaMA, achieves GPT-4 level performance.&lt;/p&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2305.15541&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/gblackout/LogicLLaMA&#34;&gt;Github&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/datasets/yuan-yang/MALLS-v0&#34;&gt;Dataset&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/yuan-yang&#34;&gt;Weights&lt;/a&gt;]&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/prj6/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/prj6/</guid>
      <description>&lt;p&gt;Many works show LLMs are good at reasoning, but is it true?
Can the LLMs reason complex and ambiguous programs using program?
It turns out the answer is no.&lt;/p&gt;
&lt;p&gt;We introduce the &lt;em&gt;reasoning in the wild&lt;/em&gt; task, where an LLM is tasked
to solve a reasoning problem of unknown type
by identifying the sub-problems and their corresponding formalisms,  and writing a program
to solve each sub-problem, guided by a &lt;em&gt;tactic&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2406.13764&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/gblackout/Reason-in-the-Wild&#34;&gt;Github&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/datasets/yuan-yang/ReWild&#34;&gt;Data&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/yuan-yang&#34;&gt;Model&lt;/a&gt;]&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/prj7/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/prj7/</guid>
      <description>&lt;p&gt;LLMs nowadays can process multimodal data, long documents, use tools, and browse web.
Can we integrate all these and make a language model OS? Where, the LLM acts as a CPU that processes data stored in a context window (RAM).&lt;/p&gt;
&lt;p&gt;We argue the the key challenge towards LM OS is managing the life-long context and ensuring statefulness across sessions.
To address this, we introduce compressor-retriever, a model-agnostic architecture designed for life-long context management.
Our approach exclusively uses the base model&#39;s forward function to compress and retrieve context, ensuring end-to-end differentiability.
Preliminary experiments demonstrate the effectiveness of this architecture in in-context learning tasks, marking a step towards the development of a fully stateful LLM OS.&lt;/p&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2409.01495&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/gblackout/LM-OS&#34;&gt;Github&lt;/a&gt;]&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/prj8/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/prj8/</guid>
      <description>&lt;p&gt;Casually working on LLM-based cyber waifu/husbando ;)&lt;/p&gt;
&lt;p&gt;[&lt;a href=&#34;https://github.com/gblackout/prj-cw&#34;&gt;Github&lt;/a&gt;]&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
