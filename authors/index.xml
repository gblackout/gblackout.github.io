<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Authors | Yuan Yang</title>
    <link>/authors/</link>
      <atom:link href="/authors/index.xml" rel="self" type="application/rss+xml" />
    <description>Authors</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 01 Jan 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Authors</title>
      <link>/authors/</link>
    </image>
    
    <item>
      <title>Hanjun Dai</title>
      <link>/authors/hanjun-dai/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/authors/hanjun-dai/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Le Song</title>
      <link>/authors/le-song/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/authors/le-song/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mayur Naik</title>
      <link>/authors/mayur-naik/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/authors/mayur-naik/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Xujie Si&lt;sup&gt;&amp;#42;&lt;/sup&gt;</title>
      <link>/authors/xujie-sisup#42/sup/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/authors/xujie-sisup#42/sup/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Yuan Yang</title>
      <link>/authors/yuan-yang/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/authors/yuan-yang/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Yuan Yang&lt;sup&gt;&amp;#42;&lt;/sup&gt;</title>
      <link>/authors/yuan-yangsup#42/sup/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/authors/yuan-yangsup#42/sup/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Carol Cheng</title>
      <link>/authors/carol-cheng/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/carol-cheng/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Christy Li</title>
      <link>/authors/christy-li/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/christy-li/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Eric Nyberg</title>
      <link>/authors/eric-nyberg/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/eric-nyberg/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Eric Xing</title>
      <link>/authors/eric-xing/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/eric-xing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hongbao Zhang</title>
      <link>/authors/hongbao-zhang/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/hongbao-zhang/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jingcheng Yu</title>
      <link>/authors/jingcheng-yu/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/jingcheng-yu/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Pengtao Xie</title>
      <link>/authors/pengtao-xie/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/pengtao-xie/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Xiaoyao Xu</title>
      <link>/authors/xiaoyao-xu/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/xiaoyao-xu/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Xin Gao</title>
      <link>/authors/xin-gao/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/xin-gao/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Y. Yang</title>
      <link>/authors/y.-yang/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/y.-yang/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Ye Hu</title>
      <link>/authors/ye-hu/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      <guid>/authors/ye-hu/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jianfei Chen</title>
      <link>/authors/jianfei-chen/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>/authors/jianfei-chen/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Jun Zhu</title>
      <link>/authors/jun-zhu/</link>
      <pubDate>Fri, 01 Jan 2016 00:00:00 +0000</pubDate>
      <guid>/authors/jun-zhu/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Di Zhao</title>
      <link>/authors/di-zhao/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>/authors/di-zhao/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hong Yi Li</title>
      <link>/authors/hong-yi-li/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>/authors/hong-yi-li/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/admin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/admin/</guid>
      <description>&lt;p&gt;I&#39;m a 5th year Machine Learning PhD at Georgia Tech supervised by Prof. &lt;a href=&#34;https://fekri.ece.gatech.edu/&#34;&gt;Faramarz Fekri&lt;/a&gt; (Previously by &lt;a href=&#34;https://scholar.google.com/citations?user=Xl4E0CsAAAAJ&amp;amp;hl=en&#34;&gt;Le Song&lt;/a&gt;). I received my MS in Computational Data Science from CMU in 2017 and BEng in Software Engineering from Beihang Univ. in 2016.&lt;/p&gt;
&lt;p&gt;My research focuses on developing controllable, interpretable, and data-efficient ML models via logic reasoning.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I study fundamental problems of performing inductive and deductive logic reasoning on knowledge graphs and have proposed several differentiable graph reasoning models.&lt;/li&gt;
&lt;li&gt;I work on several frameworks that utilize logic reasoning for automatic data labeling and adversarial defense for vision models.&lt;/li&gt;
&lt;li&gt;My recent research focuses on incorporating logic reasoning into large language models for controllable and grounded text generation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Research topics&lt;/strong&gt;: knowledge graph, logic reasoning, NLP, and large language models&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/prj1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/prj1/</guid>
      <description>&lt;p&gt;Temporal data such as video and driving logs are widely studied in tasks such as video
understanding and autonomous driving.&lt;/p&gt;
&lt;p&gt;We develop a reasoning framework that detects inductive patterns in temporal data via neural-logic
methodology. The framework aims to assist the training of modern ML models by inducing patterns for accurate grounding
with fewer data. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Summarizing recipes from cooking instruction videos for caption generation.&lt;/li&gt;
&lt;li&gt;Detecting and summarizing human driver&#39;s behavior from the driving logs for imitation learning of an autonomous driving agent.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/prj2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/prj2/</guid>
      <description>&lt;p&gt;Modern ML models can achieve amazing performance in many tasks. However, they require a large amount of labeled data
to train and their outputs are not self-explanatory for human users.&lt;/p&gt;
&lt;p&gt;We study this problem for graph reasoning models. We propose a learning-by-asking
framework, namely LogicQA, that trains the model by interactively asking questions to an oracle. Under the hood,
verified questions are used to label the data automatically, leading to order of magnitude better data efficiency.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/prj3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/prj3/</guid>
      <description>&lt;p&gt;Deductive and inductive reasoning are the critical tasks for many knowledge graphs applications. The former learns
to infer new facts using the existing knowledge; the latter summarizes (or induces) the knowledge using the
existing facts. We studied and proposed GNN- and logic-based models to address these issues respectively.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/prj4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/prj4/</guid>
      <description>&lt;p&gt;Deep vision models are successfully employed in many applications, but they are vulnerable to adversarial
examples. Existing defense methods are either limited to specific attacks types or are too complex for practical models.&lt;/p&gt;
&lt;p&gt;To this end, we propose &lt;em&gt;logic adversarial defense&lt;/em&gt;, a framework that utilizes the scene graph of the image to detect
object labels that are out-of-place in the context. Our framework is model-agnostic and effective against localized
attacks such as &lt;em&gt;adversarial patch&lt;/em&gt;. Moreover, it produces human-readable explanations as to why the system is attacked.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/authors/prj5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/authors/prj5/</guid>
      <description>&lt;p&gt;One of the major bottlenecks for logic-based NLP systems is the lack of a reliable translation model that
maps natural language (NL) to the corresponding first-order logic (FOL) representation.&lt;/p&gt;
&lt;p&gt;We approach this longstanding challenge by harnessing the power of LLMs. We create a high-quality
sentence-level NL-FOL pair dataset (MALLS) from GPT-4. We then propose an SFT+RLHF framework that finetunes
LLaMA models for NL-FOL translation task. The resulting model, namely LogicLLaMA, achieves GPT-4 level performance.&lt;/p&gt;
&lt;p&gt;[&lt;a href=&#34;https://arxiv.org/abs/2305.15541&#34;&gt;Paper&lt;/a&gt;] [&lt;a href=&#34;https://github.com/gblackout/LogicLLaMA&#34;&gt;Github&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/datasets/yuan-yang/MALLS-v0&#34;&gt;Dataset&lt;/a&gt;] [&lt;a href=&#34;https://huggingface.co/yuan-yang&#34;&gt;Weights&lt;/a&gt;]&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
